{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
    "        \n",
    "class StreamingThread(threading.Thread):\n",
    "    def __init__(self, ssc):\n",
    "        super().__init__()\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        self.ssc.start()\n",
    "        self.ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-65PI680:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-65PI680:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1718f0b1700>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType\n",
    "import fasttext\n",
    "import re\n",
    "from pyspark.sql.types import IntegerType,NumericType\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotes_baus =['SpongeWait', 'bausEZ', 'PETTHEBAUS', 'BRAMBLUS', 'bausPushups', 'KrugsUp', 'BausDonut', 'DaBaus', 'Babush', 'PPogo', 'FeelsHentai', 'SadgeJAM', 'Leanin', 'forsenCD', 'flashAbuser', 'Yoking', 'KKled', 'imposterSus', 'PepeLaffing', 'SirO', 'Svin', 'BABUS', 'PEPW', 'robLick', 'ezChamp', 'Diddles', 'BorpaFoundYou', 'Yoker', 'CLEAN', 'PepeUff', 'peepoChicken', 'vibePLS', 'Chatters', 'WEIRD', 'MODS', 'COCKA', 'DodgeAbusers', 'WeirdChamping', 'JoeBiden', 'TeaTime', 'Shilling', 'YEPCock', 'Weebs', 'IMustLean', 'ClubDance', 'BausBoomer', 'YEPJAM', 'PeterChamp', 'DONUT', 'batJAM', 'DESPAIR', 'lizardPls', 'bausL', 'YEBB', 'BOOBA', 'SadChamp', 'RIOT', 'IRELIAING', 'INSANECAT', 'Cummies', 'Duck', 'SCOOBA', 'Corpa', 'MUTE', 'Boomba', 'ABDULpls', 'MLADY', 'NODDERS', 'peepoHey', 'peepoTalk', 'FeelsWeakMan', 'TriBoom', 'PepegaDriving', 'gachiHYPER', 'Jammies', 'Nerdge', 'borpaSpin', 'KKool', 'peepoRasp', 'pepeMeltdown', 'Peeporiot', 'OOOO', 'PogO', 'PauseChamp', 'Tssk', 'furryRun', 'SION', 'gankAbuser', 'Gaspnt', 'modSheck', 'zhonyasAbuser', 'aniBlush', 'pepeP', 'NOOO', 'FLUSH', 'AYAYA', 'Haha', 'lickR', 'lickL', 'PagWoman', 'SionPassive', 'WeirdShamp', 'EatPoo', 'OMEGALOOOOL', 'Susge', 'Pepeg', 'poopoHappy']\n",
    "emotes_adept = ['adeptTEA', 'mariRICH', 'peepoRun', 'gachiBASS', 'PepePls', 'Clap', 'pepeJAM', 'EZ', 'HYPERCLAP', 'PepegaPls', 'PepoDance', 'peepoPooPoo', 'pepeD', 'nymnCorn', 'pepeL', 'GuitarTime', 'gachiHYPER', 'ppOverheat', 'FeelsStrongJAM', 'sumSmash', 'COGGERS', 'forsenPls', 'ppHop', 'FeelsRainMan', 'xqcSlam', 'tenseSmash', 'CarlosPls', 'TranceGirls', 'FeelsLagMan', 'TriDance', 'PepegaAim', 'xqcOut', 'pepeMeltdown', 'TeaTime', 'peepoLeave', 'yikesJAM', 'peepoGiggles', 'peepoClap', 'WAYTOODANK', 'OuttaPocket', 'pepeCD', 'HACKERMANS', 'PepegaCredit', 'PepoG', 'PepeMods', 'DonoWall', 'PERIODT', 'BOOBA', 'Drake', 'modCheck', 'monkaSTEER', 'peepoShy', 'peepoFinger', 'PepeLa', 'Jammies', 'NOPERS', 'Chatting', 'Hmmm', 'Copium', 'Madge', 'Prayge', 'CLEAN', 'COWdance', 'DojaDance', 'Awkward', 'BLUBBERS', 'ppSmoke', 'peepoDJ', 'Susge', 'pugPls', 'peepoRiot', 'POLICE', 'lebronJAM', 'NODDERS', 'dojaJAM', 'MeganSus', 'catJAM', 'DinkDonk', 'GIGACHAD', 'HUHH', 'RIPBOZO', 'LOLOL', 'peepoBlonket', 'AlienPls', 'PepeFlushed', 'peepoTalk', 'peepoStir', 'Crying', 'oopTea', 'NOOO', 'pepeW', 'DIESOFCRINGE', 'Sussy', 'VeryPog', 'ppPoof', 'Bedge', 'ddHuh', 'Wokege', 'TomatoTime', 'catAwkward']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result = globals()['my_model'].transform(df)\n",
    "# df_result.show()\n",
    "\n",
    "def identify_emotes_baus(text):\n",
    "    return len([1 for word in emotes_baus if re.search(word, text)])\n",
    "def identify_emotes_adept(text):\n",
    "    return len([1 for word in emotes_adept if re.search(word, text)])\n",
    "\n",
    "def preproc(msg):\n",
    "    msg = msg.lower()\n",
    "    msg = re.sub(r'[^\\s\\w]', '', msg)\n",
    "    return msg\n",
    "    \n",
    "def Pred_probability(msg):\n",
    "    msg = preproc(msg)\n",
    "    model  = fasttext.load_model('ft.bin')\n",
    "    pred = model.predict(msg.lower())[1]\n",
    "    name = model.predict(msg.lower())[0][0]\n",
    "    if name == '__label__thebausffs':\n",
    "        pred = -pred\n",
    "    else:\n",
    "        pred = pred\n",
    "    return float(pred)\n",
    "\n",
    "def preproc(msg):\n",
    "    msg = msg.lower()\n",
    "    msg = re.sub(r'[^\\s\\w]', '', msg)\n",
    "    return msg\n",
    "\n",
    "def Predicted_Channel(x):\n",
    "    if int(x) == 1:\n",
    "        return 'adeptthebest'\n",
    "    else:\n",
    "        return 'thebausffs'\n",
    "    return result\n",
    "\n",
    "#predict_udf = udf(pred_chan,StringType())\n",
    "preproc_udf = udf(preproc,StringType())\n",
    "emotes_baus_udf =  udf(identify_emotes_baus, StringType())\n",
    "emotes_adept_udf =  udf(identify_emotes_adept, StringType())\n",
    "transform_probability_udf = udf(lambda z: Pred_probability(z)) \n",
    "Predicted_Channel_udf = udf(Predicted_Channel, StringType())\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        print('Empty')\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    df = df.withColumn('msg', preproc_udf('message'))\n",
    "    df = df.withColumn('Probability', transform_probability_udf('message').cast('float'))\n",
    "    df = df.withColumn('AdeptEmote', emotes_adept_udf('message').cast('int'))\n",
    "    df = df.withColumn('BausEmote', emotes_baus_udf('message').cast('int'))\n",
    "    #df = df[['channel', 'msg','Probability','features','AdeptEmote','BausEmote']]\n",
    "    assembler = VectorAssembler(inputCols=['BausEmote', 'AdeptEmote','Probability'],outputCol=\"features\")\n",
    "    df = assembler.transform(df)\n",
    "    #df = df.withColumn('Features', spDF['features'])\n",
    "    model = LogisticRegressionModel.load('notebooks\\\\RegModel')\n",
    "    df = model.transform(df)\n",
    "    df = df.withColumn('Predicted', Predicted_Channel_udf('prediction'))\n",
    "    df = df[['channel','Predicted', 'message']]\n",
    "    df.show()\n",
    "    df.write.csv('Predictions', mode=\"append\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"localhost\", 8080)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "========= 2022-05-24 17:38:45 =========\n",
      "+-----------+----------+--------------------+\n",
      "|    channel| Predicted|             message|\n",
      "+-----------+----------+--------------------+\n",
      "|#thebausffs|thebausffs|@falendalle hate ...|\n",
      "|#thebausffs|thebausffs|                Mots|\n",
      "|#thebausffs|thebausffs|                  -2|\n",
      "+-----------+----------+--------------------+\n",
      "\n",
      "Empty\n",
      "Empty\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
