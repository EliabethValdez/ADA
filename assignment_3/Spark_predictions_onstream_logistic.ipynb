{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SJ7loA5RDHU"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "\n",
        "# Helper thread to avoid the Spark StreamingContext from blocking Jupyter\n",
        "        \n",
        "class StreamingThread(threading.Thread):\n",
        "    def __init__(self, ssc):\n",
        "        super().__init__()\n",
        "        self.ssc = ssc\n",
        "    def run(self):\n",
        "        self.ssc.start()\n",
        "        self.ssc.awaitTermination()\n",
        "    def stop(self):\n",
        "        print('----- Stopping... this may take a few seconds -----')\n",
        "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "EWLAHnnJRDHW",
        "outputId": "d3ad3adb-bab7-423c-b48f-baf98f1c2c9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://DESKTOP-65PI680:4044\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySparkShell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=PySparkShell>"
            ]
          },
          "execution_count": 299,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QdiM7u9RDHX",
        "outputId": "4c35c1e8-deef-4403-c73d-b30f860e7d22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://DESKTOP-65PI680:4044\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySparkShell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x1f3d8821700>"
            ]
          },
          "execution_count": 300,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIUCDPY9RDHY"
      },
      "outputs": [],
      "source": [
        "from pyspark.streaming import StreamingContext\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import udf, struct, array, col, lit\n",
        "from pyspark.sql.types import StringType\n",
        "import fasttext\n",
        "import re\n",
        "from pyspark.sql.types import IntegerType,NumericType\n",
        "import pandas as pd\n",
        "from pyspark.ml.classification import LogisticRegressionModel\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3gy0fgVRDHZ"
      },
      "outputs": [],
      "source": [
        "emotes_baus =['SpongeWait', 'bausEZ', 'PETTHEBAUS', 'BRAMBLUS', 'bausPushups', 'KrugsUp', 'BausDonut', 'DaBaus', 'Babush', 'PPogo', 'FeelsHentai', 'SadgeJAM', 'Leanin', 'forsenCD', 'flashAbuser', 'Yoking', 'KKled', 'imposterSus', 'PepeLaffing', 'SirO', 'Svin', 'BABUS', 'PEPW', 'robLick', 'ezChamp', 'Diddles', 'BorpaFoundYou', 'Yoker', 'CLEAN', 'PepeUff', 'peepoChicken', 'vibePLS', 'Chatters', 'WEIRD', 'MODS', 'COCKA', 'DodgeAbusers', 'WeirdChamping', 'JoeBiden', 'TeaTime', 'Shilling', 'YEPCock', 'Weebs', 'IMustLean', 'ClubDance', 'BausBoomer', 'YEPJAM', 'PeterChamp', 'DONUT', 'batJAM', 'DESPAIR', 'lizardPls', 'bausL', 'YEBB', 'BOOBA', 'SadChamp', 'RIOT', 'IRELIAING', 'INSANECAT', 'Cummies', 'Duck', 'SCOOBA', 'Corpa', 'MUTE', 'Boomba', 'ABDULpls', 'MLADY', 'NODDERS', 'peepoHey', 'peepoTalk', 'FeelsWeakMan', 'TriBoom', 'PepegaDriving', 'gachiHYPER', 'Jammies', 'Nerdge', 'borpaSpin', 'KKool', 'peepoRasp', 'pepeMeltdown', 'Peeporiot', 'OOOO', 'PogO', 'PauseChamp', 'Tssk', 'furryRun', 'SION', 'gankAbuser', 'Gaspnt', 'modSheck', 'zhonyasAbuser', 'aniBlush', 'pepeP', 'NOOO', 'FLUSH', 'AYAYA', 'Haha', 'lickR', 'lickL', 'PagWoman', 'SionPassive', 'WeirdShamp', 'EatPoo', 'OMEGALOOOOL', 'Susge', 'Pepeg', 'poopoHappy']\n",
        "emotes_adept = ['adeptTEA', 'mariRICH', 'peepoRun', 'gachiBASS', 'PepePls', 'Clap', 'pepeJAM', 'EZ', 'HYPERCLAP', 'PepegaPls', 'PepoDance', 'peepoPooPoo', 'pepeD', 'nymnCorn', 'pepeL', 'GuitarTime', 'gachiHYPER', 'ppOverheat', 'FeelsStrongJAM', 'sumSmash', 'COGGERS', 'forsenPls', 'ppHop', 'FeelsRainMan', 'xqcSlam', 'tenseSmash', 'CarlosPls', 'TranceGirls', 'FeelsLagMan', 'TriDance', 'PepegaAim', 'xqcOut', 'pepeMeltdown', 'TeaTime', 'peepoLeave', 'yikesJAM', 'peepoGiggles', 'peepoClap', 'WAYTOODANK', 'OuttaPocket', 'pepeCD', 'HACKERMANS', 'PepegaCredit', 'PepoG', 'PepeMods', 'DonoWall', 'PERIODT', 'BOOBA', 'Drake', 'modCheck', 'monkaSTEER', 'peepoShy', 'peepoFinger', 'PepeLa', 'Jammies', 'NOPERS', 'Chatting', 'Hmmm', 'Copium', 'Madge', 'Prayge', 'CLEAN', 'COWdance', 'DojaDance', 'Awkward', 'BLUBBERS', 'ppSmoke', 'peepoDJ', 'Susge', 'pugPls', 'peepoRiot', 'POLICE', 'lebronJAM', 'NODDERS', 'dojaJAM', 'MeganSus', 'catJAM', 'DinkDonk', 'GIGACHAD', 'HUHH', 'RIPBOZO', 'LOLOL', 'peepoBlonket', 'AlienPls', 'PepeFlushed', 'peepoTalk', 'peepoStir', 'Crying', 'oopTea', 'NOOO', 'pepeW', 'DIESOFCRINGE', 'Sussy', 'VeryPog', 'ppPoof', 'Bedge', 'ddHuh', 'Wokege', 'TomatoTime', 'catAwkward']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOhVWqxnRDHa"
      },
      "outputs": [],
      "source": [
        "# df_result = globals()['my_model'].transform(df)\n",
        "# df_result.show()\n",
        "\n",
        "def identify_emotes_baus(text):\n",
        "    return len([1 for word in emotes_baus if re.search(word, text)])\n",
        "def identify_emotes_adept(text):\n",
        "    return len([1 for word in emotes_adept if re.search(word, text)])\n",
        "\n",
        "def preproc(msg):\n",
        "    msg = msg.lower()\n",
        "    msg = re.sub(r'[^\\s\\w]', '', msg)\n",
        "    return msg\n",
        "    \n",
        "def Pred_probability(msg):\n",
        "    msg = preproc(msg)\n",
        "    model  = fasttext.load_model('ft.bin')\n",
        "    pred = model.predict(msg.lower())[1]\n",
        "    name = model.predict(msg.lower())[0][0]\n",
        "    if name == '__label__thebausffs':\n",
        "        pred = -pred\n",
        "    else:\n",
        "        pred = pred\n",
        "    return float(pred)\n",
        "\n",
        "def preproc(msg):\n",
        "    msg = msg.lower()\n",
        "    msg = re.sub(r'[^\\s\\w]', '', msg)\n",
        "    return msg\n",
        "\n",
        "def Predicted_Channel(x):\n",
        "    if int(x) == 1:\n",
        "        return 'adeptthebest'\n",
        "    else:\n",
        "        return 'thebausffs'\n",
        "    return result\n",
        "\n",
        "#predict_udf = udf(pred_chan,StringType())\n",
        "preproc_udf = udf(preproc,StringType())\n",
        "emotes_baus_udf =  udf(identify_emotes_baus, StringType())\n",
        "emotes_adept_udf =  udf(identify_emotes_adept, StringType())\n",
        "transform_probability_udf = udf(lambda z: Pred_probability(z)) \n",
        "Predicted_Channel_udf = udf(Predicted_Channel, StringType())\n",
        "def process(time, rdd):\n",
        "    if rdd.isEmpty():\n",
        "        print('Empty')\n",
        "        return\n",
        "    \n",
        "    print(\"========= %s =========\" % str(time))\n",
        "    # Convert to data frame\n",
        "    df = spark.read.json(rdd)\n",
        "    df = df.withColumn('msg', preproc_udf('message'))\n",
        "    df = df.withColumn('Probability', transform_probability_udf('message').cast('float'))\n",
        "    df = df.withColumn('AdeptEmote', emotes_adept_udf('message').cast('int'))\n",
        "    df = df.withColumn('BausEmote', emotes_baus_udf('message').cast('int'))\n",
        "    #df = df[['channel', 'msg','Probability','features','AdeptEmote','BausEmote']]\n",
        "    assembler = VectorAssembler(inputCols=['BausEmote', 'AdeptEmote','Probability'],outputCol=\"features\")\n",
        "    df = assembler.transform(df)\n",
        "    #df = df.withColumn('Features', spDF['features'])\n",
        "    model = LogisticRegressionModel.load('notebooks\\\\RegModel')\n",
        "    df = model.transform(df)\n",
        "    df = df.withColumn('Predicted', Predicted_Channel_udf('prediction'))\n",
        "    df = df[['channel','Predicted', 'message']]\n",
        "    df.show()\n",
        "    #df.write.csv('Predictions', mode=\"append\", header=\"true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vMLjHMjRDHb"
      },
      "outputs": [],
      "source": [
        "ssc = StreamingContext(sc, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "C7nKLH_vRDHc"
      },
      "outputs": [],
      "source": [
        "lines = ssc.socketTextStream(\"localhost\", 8080)\n",
        "lines.foreachRDD(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "rLzqzWXkRDHc"
      },
      "outputs": [],
      "source": [
        "ssc_t = StreamingThread(ssc)\n",
        "ssc_t.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "U2J0isAFRDHd",
        "outputId": "e0967ce6-2d0a-4aec-9903-c0667f869af1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Stopping... this may take a few seconds -----\n",
            "========= 2022-05-24 15:25:35 =========\n",
            "+----------+------------+--------------------+\n",
            "|   channel|   Predicted|             message|\n",
            "+----------+------------+--------------------+\n",
            "|#asmongold|  thebausffs|              LMAOOO|\n",
            "|#asmongold|  thebausffs|             ooof D:|\n",
            "|#asmongold|adeptthebest|                KEKW|\n",
            "|#loltyler1|  thebausffs|    IM LATE BELIEVER|\n",
            "|#asmongold|adeptthebest|            OMEGALUL|\n",
            "|#asmongold|  thebausffs|                 OMG|\n",
            "|#asmongold|adeptthebest|            GIGACHAD|\n",
            "|#asmongold|adeptthebest|         Mega Mares!|\n",
            "|#asmongold|adeptthebest|           xqcHYPERF|\n",
            "|#asmongold|  thebausffs|             PLEDGED|\n",
            "|#asmongold|adeptthebest|            OMEGALUL|\n",
            "|#asmongold|adeptthebest|     LUL LUL LUL LUL|\n",
            "|#asmongold|adeptthebest|                KEKW|\n",
            "|#asmongold|adeptthebest|         PLEDGE CARD|\n",
            "|#asmongold|adeptthebest|      KEKW KEKW KEKW|\n",
            "|#asmongold|  thebausffs|   LMAOOOOOOOOOOOOOO|\n",
            "|#asmongold|adeptthebest|Think they’re doi...|\n",
            "|#asmongold|  thebausffs|                Haha|\n",
            "|#asmongold|adeptthebest|Yikes didnt even ...|\n",
            "|#asmongold|  thebausffs|                 LUL|\n",
            "+----------+------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Empty\n",
            "Empty\n"
          ]
        }
      ],
      "source": [
        "ssc_t.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIfONTs6RDHd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Spark_predictions_onstream_logistic.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}